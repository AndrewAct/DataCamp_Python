# # 8/7/2020
# Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as model. Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch.
# Compile your model using 'adam' as the optimizer and 'categorical_crossentropy' for the loss. To see what fraction of predictions are correct (the accuracy) in each epoch, specify the additional keyword argument metrics=['accuracy'] in model.compile().
# Fit the model using the predictors and target. Create a validation split of 30% (or 0.3). This will be reported in each epoch.

# Save the number of columns in predictors: n_cols
n_cols = predictors.shape[1]
input_shape = (n_cols,)

# Specify the model
model = Sequential()
model.add(Dense(100, activation='relu', input_shape = input_shape))
model.add(Dense(100, activation='relu'))
model.add(Dense(2, activation='softmax'))

# Compile the model
model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

# Fit the model
hist = model.fit(predictors, target, validation_split = 0.3)


# <script.py> output:
#     Train on 623 samples, validate on 268 samples
#     Epoch 1/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 3.3028 - acc: 0.4062
# 448/623 [====================>.........] - ETA: 0s - loss: 1.3709 - acc: 0.5737
# 623/623 [==============================] - 0s - loss: 1.2788 - acc: 0.5987 - val_loss: 0.6318 - val_acc: 0.7052
#     Epoch 2/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.6427 - acc: 0.7188
# 448/623 [====================>.........] - ETA: 0s - loss: 0.6409 - acc: 0.6719
# 623/623 [==============================] - 0s - loss: 0.6683 - acc: 0.6517 - val_loss: 0.5947 - val_acc: 0.7239
#     Epoch 3/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.6040 - acc: 0.6875
# 544/623 [=========================>....] - ETA: 0s - loss: 0.6619 - acc: 0.6342
# 623/623 [==============================] - 0s - loss: 0.6541 - acc: 0.6485 - val_loss: 0.5448 - val_acc: 0.7388
#     Epoch 4/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.5452 - acc: 0.7812
# 512/623 [=======================>......] - ETA: 0s - loss: 0.6051 - acc: 0.6738
# 623/623 [==============================] - 0s - loss: 0.6215 - acc: 0.6709 - val_loss: 0.6458 - val_acc: 0.7127
#     Epoch 5/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.6115 - acc: 0.6562
# 544/623 [=========================>....] - ETA: 0s - loss: 0.8230 - acc: 0.6415
# 623/623 [==============================] - 0s - loss: 0.8182 - acc: 0.6276 - val_loss: 0.6596 - val_acc: 0.6418
#     Epoch 6/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.6189 - acc: 0.6250
# 544/623 [=========================>....] - ETA: 0s - loss: 0.6857 - acc: 0.6140
# 623/623 [==============================] - 0s - loss: 0.6757 - acc: 0.6212 - val_loss: 0.5179 - val_acc: 0.7537
#     Epoch 7/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.5323 - acc: 0.7500
# 512/623 [=======================>......] - ETA: 0s - loss: 0.6084 - acc: 0.6855
# 623/623 [==============================] - 0s - loss: 0.5968 - acc: 0.6934 - val_loss: 0.5047 - val_acc: 0.7201
#     Epoch 8/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.6106 - acc: 0.7500
# 416/623 [===================>..........] - ETA: 0s - loss: 0.5760 - acc: 0.7188
# 623/623 [==============================] - 0s - loss: 0.5909 - acc: 0.6902 - val_loss: 0.5304 - val_acc: 0.7388
#     Epoch 9/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.5689 - acc: 0.7500
# 623/623 [==============================] - 0s - loss: 0.7093 - acc: 0.6597 - val_loss: 0.6259 - val_acc: 0.6866
#     Epoch 10/10
    
#  32/623 [>.............................] - ETA: 0s - loss: 0.4904 - acc: 0.7812
# 623/623 [==============================] - 0s - loss: 0.6173 - acc: 0.6982 - val_loss: 0.5320 - val_acc: 0.7500
